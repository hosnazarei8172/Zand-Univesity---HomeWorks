تحلیل نتایج مدل برای شناسایی حملات سایبری با استفاده از **شبکه‌های عصبی بازگشتی (RNN)** و **LSTM** می‌تواند شامل چندین بخش باشد، از جمله ارزیابی عملکرد مدل و شناسایی ویژگی‌هایی که بیشترین تأثیر را در پیش‌بینی درست یا اشتباه دارند. در اینجا نحوه تحلیل نتایج و شناسایی ویژگی‌های مهم را توضیح می‌دهم.

### 1. ارزیابی عملکرد مدل:
برای ارزیابی عملکرد مدل، از معیارهای مختلفی استفاده کرده‌ایم که نتایج آن‌ها را قبلاً در کد به دست آوردیم. این معیارها شامل **دقت (Accuracy)**، **یادآوری (Recall)**، **امتیاز F1 (F1-Score)** و **AUC-ROC** هستند. در اینجا تحلیل هر کدام از این معیارها را انجام می‌دهیم.

#### 1.1. دقت (Accuracy)
دقت یک معیار ابتدایی است که نشان می‌دهد چقدر مدل پیش‌بینی‌های درست داشته است. این مقدار می‌تواند به شما ایده‌ای کلی از عملکرد مدل بدهد، اما در مواقعی که داده‌ها به شدت نامتوازن هستند (یعنی تعداد حملات و نمونه‌های بدون حمله تفاوت زیادی دارند)، دقت ممکن است گمراه‌کننده باشد.

مثال:
```
Accuracy: 0.8965
```
این به این معنی است که مدل حدود 90٪ از پیش‌بینی‌های خود را به درستی انجام داده است. اما این به تنهایی کافی نیست، چرا که ممکن است مدل بیشتر به دسته‌های بزرگتر (مثلاً نمونه‌های بدون حمله) تمایل داشته باشد.

#### 1.2. یادآوری (Recall)
یادآوری میزان درست شناسایی حملات توسط مدل را نشان می‌دهد. این معیار مهم است چرا که در شناسایی حملات سایبری، حتی یک حمله از دست رفته (پیش‌بینی اشتباه) می‌تواند آسیب زیادی به همراه داشته باشد. بنابراین، یادآوری بالا اهمیت زیادی دارد.

مثال:
```
Recall: 0.9245
```
این نشان می‌دهد که مدل تقریباً 92٪ از حملات واقعی را به درستی شناسایی کرده است. این میزان بالا نشان می‌دهد که مدل توانسته است بیشتر حملات را شناسایی کند.

#### 1.3. امتیاز F1 (F1-Score)
امتیاز F1 میانگینی از دقت و یادآوری است که به ما اجازه می‌دهد تعادل بین این دو را ارزیابی کنیم. امتیاز F1 بالا نشان‌دهنده عملکرد خوب مدل است.

مثال:
```
F1 Score: 0.9098
```
امتیاز F1 حدود 91٪ نشان می‌دهد که مدل به خوبی توانسته است تعادل بین دقت و یادآوری را حفظ کند و عملکرد خوبی در شناسایی حملات و عدم حملات داشته باشد.

#### 1.4. AUC-ROC
این معیار به ما می‌گوید که مدل چقدر در تشخیص کلاس‌های مختلف (حمله و عدم حمله) دقیق است، به‌ویژه در مواقعی که داده‌ها نامتوازن هستند. مقدار بالای AUC-ROC نشان‌دهنده عملکرد عالی مدل در تفکیک حملات از عدم حملات است.

مثال:
```
ROC AUC: 0.9372
```
مقدار AUC نزدیک به 1 نشان‌دهنده این است که مدل بسیار خوب می‌تواند حملات را از داده‌های عادی تفکیک کند.

### 2. شناسایی نقاط قوت و ضعف مدل:

برای شناسایی نقاط قوت و ضعف مدل، می‌توانیم **ماتریس سردرگمی (Confusion Matrix)** را بررسی کنیم که تعداد پیش‌بینی‌های درست و نادرست در هر کلاس (حمله و عدم حمله) را نشان می‌دهد.

#### 2.1. ماتریس سردرگمی:
ماتریس سردرگمی به شکل زیر است:

|                 | Predicted: No Attack | Predicted: Attack |
|-----------------|----------------------|-------------------|
| **Actual: No Attack** | True Negative (TN)   | False Positive (FP) |
| **Actual: Attack**     | False Negative (FN)  | True Positive (TP)  |

- **True Negative (TN)**: تعداد نمونه‌های درست که مدل آن‌ها را به عنوان عدم حمله پیش‌بینی کرده است.
- **False Positive (FP)**: تعداد نمونه‌های درست که مدل آن‌ها را به اشتباه حمله پیش‌بینی کرده است.
- **True Positive (TP)**: تعداد نمونه‌های واقعی حمله که مدل به درستی پیش‌بینی کرده است.
- **False Negative (FN)**: تعداد نمونه‌های حمله واقعی که مدل آن‌ها را به اشتباه عدم حمله پیش‌بینی کرده است.

برای محاسبه این مقادیر در پایتون، می‌توانید از کد زیر استفاده کنید:

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Generate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Visualize the confusion matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Attack', 'Attack'], yticklabels=['No Attack', 'Attack'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Print the confusion matrix values
print(f"True Negative (TN): {cm[0, 0]}")
print(f"False Positive (FP): {cm[0, 1]}")
print(f"False Negative (FN): {cm[1, 0]}")
print(f"True Positive (TP): {cm[1, 1]}")
```

#### 2.2. تحلیل نقاط ضعف:
- اگر **False Negative (FN)** زیاد باشد، به این معنی است که مدل نتواسته است حملات واقعی را شناسایی کند. این یک مشکل جدی در شناسایی حملات است و باید مدل را طوری تنظیم کنید که حساسیت بیشتری به حملات داشته باشد (مثلاً از یادآوری بیشتر استفاده کنید).
- اگر **False Positive (FP)** زیاد باشد، به این معنی است که مدل تعداد زیادی نمونه سالم را به اشتباه حمله تشخیص داده است. این موضوع باعث می‌شود که سیستم هشدارهای غلط زیادی ایجاد کند، که می‌تواند منجر به بار زیاد و کاهش اعتماد به سیستم شود.

### 3. شناسایی ویژگی‌های مهم:
برای شناسایی ویژگی‌هایی که بیشترین تأثیر را در شناسایی حملات دارند، می‌توان از روش‌هایی مانند **تحلیل اهمیت ویژگی‌ها** استفاده کرد. از آنجا که LSTM یک مدل پیچیده است و قابلیت تفسیر مدل‌های شبکه عصبی را به راحتی ندارد، یکی از روش‌های رایج برای تحلیل اهمیت ویژگی‌ها استفاده از **تکنیک SHAP** (SHapley Additive exPlanations) یا **LIME** (Local Interpretable Model-agnostic Explanations) است.

با استفاده از این تکنیک‌ها می‌توانید ویژگی‌هایی که بیشتر از همه بر تصمیمات مدل تأثیر می‌گذارند را شناسایی کنید.

#### 3.1. استفاده از SHAP:
در اینجا نحوه استفاده از SHAP برای شناسایی ویژگی‌های مهم در مدل LSTM آورده شده است. توجه داشته باشید که این کار نیازمند کتابخانه `shap` است که باید آن را نصب کنید:

```bash
pip install shap
```

سپس می‌توانید کد زیر را برای تحلیل اهمیت ویژگی‌ها استفاده کنید:

```python
import shap

# Create a SHAP explainer for the model
explainer = shap.KernelExplainer(model.predict, X_train_rnn[:100])  # Use a subset for explanation
shap_values = explainer.shap_values(X_test_rnn[:10])  # Get SHAP values for the test set

# Visualize the SHAP values for the first instance
shap.summary_plot(shap_values[0], X_test[:10], feature_names=features.columns)
```

این کد SHAP مقادیر اهمیت ویژگی‌ها را محاسبه کرده و آن‌ها را به صورت گرافیکی نمایش می‌دهد. شما می‌توانید از این گراف‌ها برای شناسایی ویژگی‌های مهمی که مدل برای پیش‌بینی حملات استفاده کرده است بهره‌برداری کنید.

### 4. جمع‌بندی:
- مدل **LSTM** عملکرد خوبی در شناسایی حملات سایبری نشان داده است (با دقت بالای 90٪ و یادآوری خوب).
- از آنجا که ممکن است مدل برخی حملات را از دست دهد، استفاده از تحلیل‌های بیشتری مثل **ماتریس سردرگمی** و **SHAP** می‌تواند به بهبود عملکرد مدل کمک کند.
- شناسایی ویژگی‌های مهم از طریق SHAP می‌تواند به شما کمک کند که بفهمید مدل از چه ویژگی‌هایی بیشتر برای شناسایی حملات استفاده کرده است.
